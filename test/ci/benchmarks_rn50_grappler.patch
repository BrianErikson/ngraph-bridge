diff --git a/scripts/tf_cnn_benchmarks/all_reduce_benchmark.py b/scripts/tf_cnn_benchmarks/all_reduce_benchmark.py
index 70735c0..9cde9f3 100644
--- a/scripts/tf_cnn_benchmarks/all_reduce_benchmark.py
+++ b/scripts/tf_cnn_benchmarks/all_reduce_benchmark.py
@@ -35,6 +35,7 @@ import time
 from absl import app
 from absl import flags as absl_flags
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
 from tensorflow.python.ops import control_flow_ops
 import benchmark_cnn
@@ -120,7 +121,7 @@ def build_all_reduce_iterations(all_device_tensors, tower_devices, variable_mgr,
       # each device.
       new_all_device_tensors = []
       for device, device_tensors in zip(tower_devices, all_device_tensors):
-        with tf.device(device):
+        with tf.compat.v1.device(device):
           new_all_device_tensors.append([
               tf.identity(t, name='identity_after_allreduce')
               for t in device_tensors
@@ -144,7 +145,7 @@ def build_all_reduce_iterations(all_device_tensors, tower_devices, variable_mgr,
   # we store the results in variables.
   ops_to_run = []
   for device, device_tensors in zip(tower_devices, all_device_tensors):
-    with tf.device(device):
+    with tf.compat.v1.device(device):
       for t in device_tensors:
         # The placeholder initial value is never run.
         var = tf.Variable(tf.placeholder(tf.float32, t.shape), collections=[])
@@ -167,7 +168,7 @@ def build_graph(tower_devices, tensor_shapes, variable_mgr, num_iters):
   """
   all_device_tensors = []
   for i, tower_device in enumerate(tower_devices):
-    with tf.device(tower_device):
+    with tf.compat.v1.device(tower_device):
       device_tensors = []
       for j, shape in enumerate(tensor_shapes):
         tensor = tf.Variable(tf.random_normal(shape, dtype=tf.float32),
diff --git a/scripts/tf_cnn_benchmarks/allreduce.py b/scripts/tf_cnn_benchmarks/allreduce.py
index 3b3ed2f..93bcc3e 100644
--- a/scripts/tf_cnn_benchmarks/allreduce.py
+++ b/scripts/tf_cnn_benchmarks/allreduce.py
@@ -21,8 +21,9 @@ import re
 
 from six.moves import xrange  # pylint: disable=redefined-builtin
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
-from tensorflow.contrib.all_reduce.python import all_reduce
+from tensorflow.python.distribute import all_reduce
 from tensorflow.python.framework import device as pydev
 from tensorflow.python.framework import ops
 from tensorflow.python.ops import collective_ops
@@ -523,13 +524,13 @@ def pack_range(key, packing, grad_vars, rng):
     for g, v in to_pack:
       variables.append(v)
       restore_shapes.append(g.shape)
-      with tf.device(g.device):
+      with tf.compat.v1.device(g.device):
         members.append(tf.reshape(g, [-1]))
     packing[key] = GradPackTuple(
         indices=range(rng[0], rng[1] + 1),
         vars=variables,
         shapes=restore_shapes)
-    with tf.device(members[0].device):
+    with tf.compat.v1.device(members[0].device):
       return tf.concat(members, 0)
 
 
@@ -546,7 +547,7 @@ def unpack_grad_tuple(gv, gpt):
      reduction.
   """
   elt_widths = [x.num_elements() for x in gpt.shapes]
-  with tf.device(gv[0][0].device):
+  with tf.compat.v1.device(gv[0][0].device):
     with tf.name_scope('unpack'):
       splits = tf.split(gv[0], elt_widths)
       unpacked_gv = []
diff --git a/scripts/tf_cnn_benchmarks/allreduce_test.py b/scripts/tf_cnn_benchmarks/allreduce_test.py
index ca48f0f..1479910 100644
--- a/scripts/tf_cnn_benchmarks/allreduce_test.py
+++ b/scripts/tf_cnn_benchmarks/allreduce_test.py
@@ -316,7 +316,7 @@ class DynamicPackingTest(test_util.TensorFlowTestCase):
       consts.append([])
       tensors.append([])
       vrbls.append([])
-      with tf.device(devname):
+      with tf.compat.v1.device(devname):
         base_value = 0
         gv_tuples = []
         for t_idx in range(0, num_tensors):
diff --git a/scripts/tf_cnn_benchmarks/batch_allreduce.py b/scripts/tf_cnn_benchmarks/batch_allreduce.py
index 6e9d0c7..be0cfcd 100644
--- a/scripts/tf_cnn_benchmarks/batch_allreduce.py
+++ b/scripts/tf_cnn_benchmarks/batch_allreduce.py
@@ -38,6 +38,7 @@ from collections import namedtuple
 
 import six
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
 from tensorflow.python.ops import data_flow_ops
 import allreduce
@@ -174,7 +175,7 @@ class CopyToDeviceAlgorithm(BatchAllReduceAlgorithm):
   def _do_batch_all_reduce(self, all_device_tensors):
     reduced_tensors = []
     for i, tensors_across_devices in enumerate(zip(*all_device_tensors)):
-      with tf.device(self._devices[i % len(self._devices)]):
+      with tf.compat.v1.device(self._devices[i % len(self._devices)]):
         reduced_tensor = _all_reduce_using_copy(tensors_across_devices,
                                                 self._use_mean)
         reduced_tensors.append(reduced_tensor)
@@ -215,29 +216,29 @@ class HierarchicalCopyAlgorithm(BatchAllReduceAlgorithm):
       # Reduce the first group.
       group_0_tensors = tensors_across_devices[group_0_begin:
                                                group_0_begin + group_size]
-      with tf.device(avail_devices[group_0_main_device]):
+      with tf.compat.v1.device(avail_devices[group_0_main_device]):
         group_0_reduced_tensor = _all_reduce_using_copy(group_0_tensors, False)
 
       # Reduce the second group.
       group_1_tensors = tensors_across_devices[group_1_begin:
                                                group_1_begin + group_size]
-      with tf.device(avail_devices[group_1_main_device]):
+      with tf.compat.v1.device(avail_devices[group_1_main_device]):
         group_1_reduced_tensor = _all_reduce_using_copy(group_1_tensors, False)
 
       # Reduce between the groups.
-      with tf.device(avail_devices[group_0_main_device]):
+      with tf.compat.v1.device(avail_devices[group_0_main_device]):
         total_reduced_tensor = _all_reduce_using_copy(
             [group_0_reduced_tensor, group_1_reduced_tensor], False)
 
       # Broadcast the result back into the root of each group.
-      with tf.device(avail_devices[group_0_main_device]):
+      with tf.compat.v1.device(avail_devices[group_0_main_device]):
         group_0_reduced_tensor_bcast = tf.identity(total_reduced_tensor)
-      with tf.device(avail_devices[group_1_main_device]):
+      with tf.compat.v1.device(avail_devices[group_1_main_device]):
         group_1_reduced_tensor_bcast = tf.identity(total_reduced_tensor)
 
       reduced_tensors_bcast = []
       for j in range(len(tensors_across_devices)):
-        with tf.device(avail_devices[j]):
+        with tf.compat.v1.device(avail_devices[j]):
           # Broadcast the result back to each member in the group from the root.
           if (group_0_main_device < group_size) == (j < group_size):
             src_device_tensor = group_0_reduced_tensor_bcast
diff --git a/scripts/tf_cnn_benchmarks/benchmark_cnn.py b/scripts/tf_cnn_benchmarks/benchmark_cnn.py
index d3b81d5..d3055f8 100644
--- a/scripts/tf_cnn_benchmarks/benchmark_cnn.py
+++ b/scripts/tf_cnn_benchmarks/benchmark_cnn.py
@@ -34,6 +34,7 @@ import numpy as np
 import six
 from six.moves import xrange  # pylint: disable=redefined-builtin
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
 from google.protobuf import text_format
 
@@ -623,7 +624,7 @@ def create_config_proto(params):
     params: Params tuple, typically created by make_params or
             make_params_from_flags.
   """
-  config = tf.ConfigProto()
+  config = tf.compat.v1.ConfigProto()
   config.allow_soft_placement = True
   if params.num_intra_threads is None:
     if params.device == 'gpu':
@@ -668,7 +669,10 @@ def create_config_proto(params):
   if params.variable_update == 'collective_all_reduce':
     config.gpu_options.experimental.num_dev_to_dev_copy_streams = 2
 
-  return config
+  import ngraph_bridge
+  config_new = ngraph_bridge.update_config(config)
+
+  return config_new
 
 
 def get_mode_from_params(params):
@@ -715,9 +719,9 @@ def benchmark_one_step(sess,
       ((trace_filename or partitioned_graph_file_prefix) and step == -2)
   )
   if need_options_and_metadata:
-    run_options = tf.RunOptions()
+    run_options = tf.compat.v1.RunOptions()
     if (trace_filename and step == -2) or should_profile:
-      run_options.trace_level = tf.RunOptions.FULL_TRACE
+      run_options.trace_level = tf.compat.v1.RunOptions.FULL_TRACE
     if partitioned_graph_file_prefix and step == -2:
       run_options.output_partition_graphs = True
     if collective_graph_key > 0:
@@ -1075,18 +1079,18 @@ def get_learning_rate(params, global_step, num_examples_per_epoch, model,
 def get_optimizer(params, learning_rate):
   """Returns the optimizer that should be used based on params."""
   if params.optimizer == 'momentum':
-    opt = tf.train.MomentumOptimizer(
+    opt = tf.compat.v1.train.MomentumOptimizer(
         learning_rate, params.momentum, use_nesterov=True)
   elif params.optimizer == 'sgd':
-    opt = tf.train.GradientDescentOptimizer(learning_rate)
+    opt = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)
   elif params.optimizer == 'rmsprop':
-    opt = tf.train.RMSPropOptimizer(
+    opt = tf.compat.v1.train.RMSPropOptimizer(
         learning_rate,
         params.rmsprop_decay,
         momentum=params.rmsprop_momentum,
         epsilon=params.rmsprop_epsilon)
   elif params.optimizer == 'adam':
-    opt = tf.train.AdamOptimizer(learning_rate, params.adam_beta1,
+    opt = tf.compat.v1.train.AdamOptimizer(learning_rate, params.adam_beta1,
                                  params.adam_beta2, params.adam_epsilon)
   else:
     raise ValueError('Optimizer "%s" was not recognized',
@@ -1560,19 +1564,19 @@ class BenchmarkCNN(object):
       dictionary.
     """
     (input_producer_op, enqueue_ops, fetches) = self._build_model()
-    saver = tf.train.Saver(self.variable_mgr.savable_variables())
-    summary_writer = tf.summary.FileWriter(self.params.eval_dir,
-                                           tf.get_default_graph())
+    saver = tf.compat.v1.train.Saver(self.variable_mgr.savable_variables())
+    summary_writer = tf.compat.v1.summary.FileWriter(self.params.eval_dir,
+                                           tf.compat.v1.get_default_graph())
     target = ''
-    local_var_init_op = tf.local_variables_initializer()
-    table_init_ops = tf.tables_initializer()
+    local_var_init_op = tf.compat.v1.local_variables_initializer()
+    table_init_ops = tf.compat.v1.tables_initializer()
     variable_mgr_init_ops = [local_var_init_op]
     if table_init_ops:
       variable_mgr_init_ops.extend([table_init_ops])
     with tf.control_dependencies([local_var_init_op]):
       variable_mgr_init_ops.extend(self.variable_mgr.get_post_init_ops())
     local_var_init_op_group = tf.group(*variable_mgr_init_ops)
-    summary_op = tf.summary.merge_all()
+    summary_op = tf.compat.v1.summary.merge_all()
     # TODO(huangyp): Check if checkpoints haven't updated for hours and abort.
     while True:
       self._eval_once(saver, summary_writer, target, local_var_init_op_group,
@@ -1585,7 +1589,7 @@ class BenchmarkCNN(object):
   def _eval_once(self, saver, summary_writer, target, local_var_init_op_group,
                  input_producer_op, enqueue_ops, fetches, summary_op):
     """Evaluate the model from a checkpoint using validation dataset."""
-    with tf.Session(
+    with tf.compat.v1.Session(
         target=target, config=create_config_proto(self.params)) as sess:
       if self.params.train_dir is None:
         raise ValueError('Trained model directory not specified')
@@ -1636,7 +1640,7 @@ class BenchmarkCNN(object):
         image_producer.done()
       accuracy_at_1 = top_1_accuracy_sum / self.num_batches
       accuracy_at_5 = top_5_accuracy_sum / self.num_batches
-      summary = tf.Summary()
+      summary = tf.compat.v1.Summary()
       summary.value.add(tag='eval/Accuracy@1', simple_value=accuracy_at_1)
       summary.value.add(tag='eval/Accuracy@5', simple_value=accuracy_at_5)
       summary_writer.add_summary(summary, global_step)
@@ -1654,7 +1658,7 @@ class BenchmarkCNN(object):
             'eval_top_1_accuracy', accuracy_at_1,
             'eval_top_5_accuracy', accuracy_at_5,
             'eval_average_examples_per_sec', images_per_sec,
-            tf.GraphKeys.GLOBAL_STEP, global_step,
+            tf.compat.v1.GraphKeys.GLOBAL_STEP, global_step,
         }
         self.benchmark_logger.log_evaluation_result(eval_result)
 
@@ -1680,7 +1684,7 @@ class BenchmarkCNN(object):
   def _unfreezable_local_variables(self, graph):
     """Get the local variables that we don't want to freeze."""
     return graph.get_collection(
-        tf.GraphKeys.LOCAL_VARIABLES,
+        tf.compat.v1.GraphKeys.LOCAL_VARIABLES,
         # We don't freeze the gpu_cached_images local variable so it won't get
         # constant folded with ops which process the input.
         scope='.*' + BenchmarkCNN.GPU_CACHED_INPUT_VARIABLE_NAME)
@@ -1707,8 +1711,8 @@ class BenchmarkCNN(object):
       execution_barrier = self.add_sync_queues_and_barrier(
           'execution_barrier_', [])
 
-    global_step = tf.train.get_global_step()
-    with tf.device(self.global_step_device), tf.name_scope('inc_global_step'):
+    global_step = tf.compat.v1.train.get_global_step()
+    with tf.compat.v1.device(self.global_step_device), tf.name_scope('inc_global_step'):
       with tf.control_dependencies([main_fetch_group]):
         fetches['inc_global_step'] = global_step.assign_add(1)
 
@@ -1723,10 +1727,10 @@ class BenchmarkCNN(object):
     with tf.name_scope('local_variable_initialization'):
       if self.forward_only_and_freeze:
         local_var_init_op = tf.variables_initializer(
-            self._unfreezable_local_variables(tf.get_default_graph()))
+            self._unfreezable_local_variables(tf.compat.v1.get_default_graph()))
       else:
-        local_var_init_op = tf.local_variables_initializer()
-    table_init_ops = tf.tables_initializer()
+        local_var_init_op = tf.compat.v1.local_variables_initializer()
+    table_init_ops = tf.compat.v1.tables_initializer()
 
     variable_manager_init_ops = [local_var_init_op]
     if table_init_ops:
@@ -1771,12 +1775,12 @@ class BenchmarkCNN(object):
     else:
       is_chief = (not self.job_name or self.task_index == 0)
 
-    summary_op = tf.summary.merge_all()
+    summary_op = tf.compat.v1.summary.merge_all()
     summary_writer = None
     if (is_chief and self.params.summary_verbosity and self.params.train_dir and
         self.params.save_summaries_steps > 0):
-      summary_writer = tf.summary.FileWriter(self.params.train_dir,
-                                             tf.get_default_graph())
+      summary_writer = tf.compat.v1.summary.FileWriter(self.params.train_dir,
+                                             tf.compat.v1.get_default_graph())
 
     # We want to start the benchmark timer right after a image_producer barrier
     # and avoids undesired waiting times on barriers.
@@ -1796,7 +1800,7 @@ class BenchmarkCNN(object):
     # Running summaries and training operations in parallel could run out of
     # GPU memory.
     if is_chief and not self.forward_only_and_freeze:
-      saver = tf.train.Saver(
+      saver = tf.compat.v1.train.Saver(
           self.variable_mgr.savable_variables(),
           save_relative_paths=True,
           max_to_keep=self.params.max_ckpts_to_keep)
@@ -1822,11 +1826,11 @@ class BenchmarkCNN(object):
     if self.params.variable_update == 'collective_all_reduce':
       # It doesn't matter what this collective_graph_key value is,
       # so long as it's > 0 and the same at every worker.
-      init_run_options = tf.RunOptions()
+      init_run_options = tf.compat.v1.RunOptions()
       init_run_options.experimental.collective_graph_key = 6
     else:
-      init_run_options = tf.RunOptions()
-    sv = tf.train.Supervisor(
+      init_run_options = tf.compat.v1.RunOptions()
+    sv = tf.compat.v1.train.Supervisor(
         # For the purpose of Supervisor, all Horovod workers are 'chiefs',
         # since we want session to be initialized symmetrically on all the
         # workers.
@@ -2049,9 +2053,9 @@ class BenchmarkCNN(object):
 
     # Freeze the graph.
     with graph.as_default():
-      with tf.Session(config=create_config_proto(self.params)) as sess:
-        sess.run(tf.global_variables_initializer())
-        sess.run(tf.local_variables_initializer())
+      with tf.compat.v1.Session(config=create_config_proto(self.params)) as sess:
+        sess.run(tf.compat.v1.global_variables_initializer())
+        sess.run(tf.compat.v1.local_variables_initializer())
         converted_graphdef = graph_util.convert_variables_to_constants(
             sess,
             graph.as_graph_def(add_shapes=True),
@@ -2144,7 +2148,7 @@ class BenchmarkCNN(object):
 
     # Not using dataset prefetching. Use a staging area to mimic the prefetching
     # behavior instead.
-    with tf.device(self.cpu_device):
+    with tf.compat.v1.device(self.cpu_device):
       if self.params.eval:
         subset = 'validation'
       else:
@@ -2206,7 +2210,7 @@ class BenchmarkCNN(object):
       seed_adjustment = hvd.rank()
     else:
       seed_adjustment = 0
-    tf.set_random_seed(self.params.tf_random_seed + seed_adjustment)
+    tf.compat.v1.set_random_seed(self.params.tf_random_seed + seed_adjustment)
     np.random.seed(4321 + seed_adjustment)
     phase_train = not (self.params.eval or self.params.forward_only)
 
@@ -2218,8 +2222,8 @@ class BenchmarkCNN(object):
     gpu_compute_stage_ops = []
     gpu_grad_stage_ops = []
 
-    with tf.device(self.global_step_device):
-      global_step = tf.train.get_or_create_global_step()
+    with tf.compat.v1.device(self.global_step_device):
+      global_step = tf.compat.v1.train.get_or_create_global_step()
       self._maybe_initialize_fp16()
 
     # Build the processing and model for the worker.
@@ -2265,7 +2269,7 @@ class BenchmarkCNN(object):
           # the moving averages for one tower. In parameter server mode, all
           # towers share a copy of the variables so we also only need to update
           # and save the moving averages once.
-          update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, name_scope)
+          update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS, name_scope)
           if self.datasets_use_prefetch:
             assert not self.variable_mgr.staging_delta_ops
           else:
@@ -2309,7 +2313,7 @@ class BenchmarkCNN(object):
 
     training_ops = []
     for d, device in enumerate(apply_gradient_devices):
-      with tf.device(device):
+      with tf.compat.v1.device(device):
         with tf.name_scope('average_loss'):
           average_loss = tf.reduce_mean(losses)
         with tf.name_scope('get_gradients_to_apply'):
@@ -2353,7 +2357,7 @@ class BenchmarkCNN(object):
               loss_scale_params)
     train_op = tf.group(*(training_ops + update_ops), name='train_ops_group')
 
-    with tf.device(self.cpu_device):
+    with tf.compat.v1.device(self.cpu_device):
       if self.task_index == 0 and self.params.summary_verbosity >= 1:
         tf.summary.scalar('learning_rate', learning_rate)
         tf.summary.scalar(self.params.loss_type_to_report, average_loss)
@@ -2410,7 +2414,7 @@ class BenchmarkCNN(object):
     assert not self.params.forward_only
     assert not self.params.staged_vars
 
-    tf.set_random_seed(self.params.tf_random_seed)
+    tf.compat.v1.set_random_seed(self.params.tf_random_seed)
     np.random.seed(4321)
     phase_train = True
 
@@ -2422,8 +2426,8 @@ class BenchmarkCNN(object):
     gpu_compute_stage_ops = []
     gpu_grad_stage_ops = []
 
-    with tf.device(self.global_step_device):
-      global_step = tf.train.get_or_create_global_step()
+    with tf.compat.v1.device(self.global_step_device):
+      global_step = tf.compat.v1.train.get_or_create_global_step()
 
     update_ops = []
     global_input_producer_op = []
@@ -2481,7 +2485,7 @@ class BenchmarkCNN(object):
             # of the variables so we also only need to update and save
             # the moving averages once.
             update_ops.extend(
-                tf.get_collection(tf.GraphKeys.UPDATE_OPS, name_scope))
+                tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS, name_scope))
             assert not self.variable_mgr.staging_delta_ops
 
     enqueue_ops = []
@@ -2530,23 +2534,23 @@ class BenchmarkCNN(object):
                          'cannot be specified. Only one should be.')
       input_shape = [self.model.get_batch_size()] + self.model.get_input_shape()
       if function_buffering_resource is not None:
-        with tf.device(self.raw_devices[rel_device_num]):
+        with tf.compat.v1.device(self.raw_devices[rel_device_num]):
           inputs, labels = data_utils.get_inputs_and_labels(
               function_buffering_resource, data_type)
           inputs = tf.reshape(inputs, shape=input_shape)
       else:
-        with tf.device(self.raw_devices[rel_device_num]):
+        with tf.compat.v1.device(self.raw_devices[rel_device_num]):
           labels, inputs = input_data
           inputs = tf.reshape(inputs, shape=input_shape)
     else:
       if not self.dataset.use_synthetic_gpu_inputs():
         input_producer_stage = input_processing_info.input_producer_stages[
             rel_device_num]
-        with tf.device(self.cpu_device):
+        with tf.compat.v1.device(self.cpu_device):
           host_inputs, host_labels = input_producer_stage.get()
           inputs_shape = host_inputs.get_shape()
           labels_shape = host_labels.get_shape()
-        with tf.device(self.raw_devices[rel_device_num]):
+        with tf.compat.v1.device(self.raw_devices[rel_device_num]):
           gpu_compute_stage = data_flow_ops.StagingArea(
               [host_inputs.dtype, host_labels.dtype],
               shapes=[inputs_shape, labels_shape])
@@ -2557,7 +2561,7 @@ class BenchmarkCNN(object):
           inputs = tf.reshape(inputs, shape=inputs_shape)
           gpu_compute_stage_ops.append(gpu_compute_stage_op)
       else:
-        with tf.device(self.raw_devices[rel_device_num]):
+        with tf.compat.v1.device(self.raw_devices[rel_device_num]):
           # Minor hack to avoid H2D copy when using synthetic data
           inputs, labels = self.model.get_synthetic_inputs_and_labels(
               BenchmarkCNN.GPU_CACHED_INPUT_VARIABLE_NAME, data_type, nclass)
@@ -2725,8 +2729,8 @@ class BenchmarkCNN(object):
         results['gradvars'] = list(zip(grads, param_refs))
 
       return results
-
-    with tf.device(self.devices[rel_device_num]):
+    # import pdb;pdb.set_trace()
+    with tf.compat.v1.device(self.devices[rel_device_num]):
       outputs = platforms_util.maybe_compile(forward_pass_and_gradients,
                                              self.params)
       logits, loss, grads = unpack_forward_pass_and_gradients_output(outputs)
@@ -2773,7 +2777,7 @@ class BenchmarkCNN(object):
       An op that should be used as control dependency before starting next step.
     """
     self.sync_queue_counter += 1
-    with tf.device(self.sync_queue_devices[(
+    with tf.compat.v1.device(self.sync_queue_devices[(
         self.sync_queue_counter % len(self.sync_queue_devices))]):
       sync_queues = [
           tf.FIFOQueue(self.num_workers, [tf.bool], shapes=[[]],
diff --git a/scripts/tf_cnn_benchmarks/benchmark_cnn_test.py b/scripts/tf_cnn_benchmarks/benchmark_cnn_test.py
index ba87f36..044d16c 100644
--- a/scripts/tf_cnn_benchmarks/benchmark_cnn_test.py
+++ b/scripts/tf_cnn_benchmarks/benchmark_cnn_test.py
@@ -1158,7 +1158,7 @@ class VariableMgrLocalReplicatedTest(tf.test.TestCase):
     tower_grads = []
     expected_sums = [0.] * num_vars
     for i, tower_device in enumerate(tower_devices):
-      with tf.device(tower_device):
+      with tf.compat.v1.device(tower_device):
         grad_vars = []
         for j in range(num_vars):
           n = num_towers * i + j
diff --git a/scripts/tf_cnn_benchmarks/convnet_builder.py b/scripts/tf_cnn_benchmarks/convnet_builder.py
index 9cbc491..2550183 100644
--- a/scripts/tf_cnn_benchmarks/convnet_builder.py
+++ b/scripts/tf_cnn_benchmarks/convnet_builder.py
@@ -22,6 +22,7 @@ import contextlib
 import numpy as np
 
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
 from tensorflow.python.layers import convolutional as conv_layers
 from tensorflow.python.layers import core as core_layers
@@ -114,7 +115,7 @@ class ConvNetBuilder(object):
     # devices and machines as type `dtype`, not `cast_dtype`. In particular,
     # this means in fp16 mode, variables are transferred as fp32 values, not
     # fp16 values, which uses extra bandwidth.
-    var = tf.get_variable(name, shape, dtype, *args, **kwargs)
+    var = tf.compat.v1.get_variable(name, shape, dtype, *args, **kwargs)
     return tf.cast(var, cast_dtype)
 
   def _conv2d_impl(self, input_layer, num_channels_in, filters, kernel_size,
@@ -160,10 +161,10 @@ class ConvNetBuilder(object):
     if num_channels_in is None:
       num_channels_in = self.top_size
     if stddev is not None and kernel_initializer is None:
-      kernel_initializer = tf.truncated_normal_initializer(stddev=stddev)
+      kernel_initializer = tf.compat.v1.truncated_normal_initializer(stddev=stddev)
     name = 'conv' + str(self.counts['conv'])
     self.counts['conv'] += 1
-    with tf.variable_scope(name):
+    with tf.compat.v1.variable_scope(name):
       strides = [1, d_height, d_width, 1]
       if self.data_format == 'NCHW':
         strides = [strides[0], strides[3], strides[1], strides[2]]
@@ -305,17 +306,17 @@ class ConvNetBuilder(object):
       num_channels_in = self.top_size
     name = 'affine' + str(self.counts['affine'])
     self.counts['affine'] += 1
-    with tf.variable_scope(name):
+    with tf.compat.v1.variable_scope(name):
       init_factor = 2. if activation == 'relu' else 1.
       stddev = stddev or np.sqrt(init_factor / num_channels_in)
       kernel = self.get_variable(
           'weights', [num_channels_in, num_out_channels],
           self.variable_dtype, self.dtype,
-          initializer=tf.truncated_normal_initializer(stddev=stddev))
+          initializer=tf.compat.v1.truncated_normal_initializer(stddev=stddev))
       biases = self.get_variable('biases', [num_out_channels],
                                  self.variable_dtype, self.dtype,
                                  initializer=tf.constant_initializer(bias))
-      logits = tf.nn.xw_plus_b(input_layer, kernel, biases)
+      logits = tf.compat.v1.nn.xw_plus_b(input_layer, kernel, biases)
       if activation == 'relu':
         affine1 = tf.nn.relu(logits, name=name)
       elif activation == 'linear' or activation is None:
@@ -333,7 +334,7 @@ class ConvNetBuilder(object):
       in_size = self.top_size
     name += str(self.counts[name])
     self.counts[name] += 1
-    with tf.variable_scope(name):
+    with tf.compat.v1.variable_scope(name):
       col_layers = []
       col_layer_sizes = []
       for c, col in enumerate(cols):
@@ -378,7 +379,7 @@ class ConvNetBuilder(object):
     else:
       self.top_size = None
     name = 'dropout' + str(self.counts['dropout'])
-    with tf.variable_scope(name):
+    with tf.compat.v1.variable_scope(name):
       if not self.phase_train:
         keep_prob = 1.0
       if self.use_tf_layers:
@@ -406,26 +407,26 @@ class ConvNetBuilder(object):
     # For moving variables, we use tf.get_variable instead of self.get_variable,
     # since self.get_variable returns the result of tf.cast which we cannot
     # assign to.
-    moving_mean = tf.get_variable('moving_mean', [num_channels],
+    moving_mean = tf.compat.v1.get_variable('moving_mean', [num_channels],
                                   tf.float32,
                                   initializer=tf.zeros_initializer(),
                                   trainable=False)
-    moving_variance = tf.get_variable('moving_variance', [num_channels],
+    moving_variance = tf.compat.v1.get_variable('moving_variance', [num_channels],
                                       tf.float32,
                                       initializer=tf.ones_initializer(),
                                       trainable=False)
     if self.phase_train:
-      bn, batch_mean, batch_variance = tf.nn.fused_batch_norm(
+      bn, batch_mean, batch_variance = tf.compat.v1.nn.fused_batch_norm(
           input_layer, gamma, beta, epsilon=epsilon,
           data_format=self.data_format, is_training=True)
       mean_update = moving_averages.assign_moving_average(
           moving_mean, batch_mean, decay=decay, zero_debias=False)
       variance_update = moving_averages.assign_moving_average(
           moving_variance, batch_variance, decay=decay, zero_debias=False)
-      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, mean_update)
-      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, variance_update)
+      tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.UPDATE_OPS, mean_update)
+      tf.compat.v1.add_to_collection(tf.compat.v1.GraphKeys.UPDATE_OPS, variance_update)
     else:
-      bn, _, _ = tf.nn.fused_batch_norm(
+      bn, _, _ = tf.compat.v1.nn.fused_batch_norm(
           input_layer, gamma, beta, mean=moving_mean,
           variance=moving_variance, epsilon=epsilon,
           data_format=self.data_format, is_training=False)
@@ -441,19 +442,20 @@ class ConvNetBuilder(object):
     name = 'batchnorm' + str(self.counts['batchnorm'])
     self.counts['batchnorm'] += 1
 
-    with tf.variable_scope(name) as scope:
-      if self.use_tf_layers:
-        bn = tf.contrib.layers.batch_norm(
-            input_layer,
-            decay=decay,
-            scale=scale,
-            epsilon=epsilon,
-            is_training=self.phase_train,
-            fused=True,
-            data_format=self.data_format,
-            scope=scope)
-      else:
-        bn = self._batch_norm_without_layers(input_layer, decay, scale, epsilon)
+    with tf.compat.v1.variable_scope(name) as scope:
+      # if self.use_tf_layers:
+      #   bn = tf.contrib.layers.batch_norm(
+      #       input_layer,
+      #       decay=decay,
+      #       scale=scale,
+      #       epsilon=epsilon,
+      #       is_training=self.phase_train,
+      #       fused=True,
+      #       data_format=self.data_format,
+      #       scope=scope)
+      # else:
+      #   bn = self._batch_norm_without_layers(input_layer, decay, scale, epsilon)
+      bn = self._batch_norm_without_layers(input_layer, decay, scale, epsilon)
     self.top_layer = bn
     self.top_size = bn.shape[3] if self.data_format == 'NHWC' else bn.shape[1]
     self.top_size = int(self.top_size)
@@ -466,3 +468,4 @@ class ConvNetBuilder(object):
     self.top_layer = tf.nn.lrn(
         self.top_layer, depth_radius, bias, alpha, beta, name=name)
     return self.top_layer
+import ngraph_bridge
diff --git a/scripts/tf_cnn_benchmarks/data_utils.py b/scripts/tf_cnn_benchmarks/data_utils.py
index 0376d0b..1cb1954 100644
--- a/scripts/tf_cnn_benchmarks/data_utils.py
+++ b/scripts/tf_cnn_benchmarks/data_utils.py
@@ -17,11 +17,11 @@
 Collection of utility methods that make CNN benchmark code use tf.data easier.
 """
 import tensorflow as tf
-
-from tensorflow.contrib.data.python.ops import batching
-from tensorflow.contrib.data.python.ops import interleave_ops
-from tensorflow.contrib.data.python.ops import prefetching_ops
-from tensorflow.contrib.data.python.ops import threadpool
+tf.compat.v1.disable_eager_execution()
+from tensorflow.python.data.experimental.ops import batching
+from tensorflow.python.data.experimental.ops import interleave_ops
+from tensorflow.python.data.experimental.ops import prefetching_ops
+from tensorflow.python.data.experimental.ops import threadpool
 from tensorflow.python.framework import function
 from tensorflow.python.platform import gfile
 
@@ -30,7 +30,7 @@ def build_prefetch_input_processing(batch_size, data_point_shape, num_splits,
                                     preprocess_fn, cpu_device, params,
                                     gpu_devices, data_type, dataset):
   """"Returns FunctionBufferingResources that do image pre(processing)."""
-  with tf.device(cpu_device):
+  with tf.compat.v1.device(cpu_device):
     if params.eval:
       subset = 'validation'
     else:
@@ -48,7 +48,7 @@ def build_prefetch_input_processing(batch_size, data_point_shape, num_splits,
         cache_data=params.cache_data,
         num_threads=params.datasets_num_private_threads)
     for device_num in range(len(gpu_devices)):
-      with tf.device(gpu_devices[device_num]):
+      with tf.compat.v1.device(gpu_devices[device_num]):
         buffer_resource_handle = prefetching_ops.function_buffering_resource(
             f=remote_fn,
             output_types=[data_type, tf.int32],
diff --git a/scripts/tf_cnn_benchmarks/models/mobilenet.py b/scripts/tf_cnn_benchmarks/models/mobilenet.py
index 4e9b2d0..a203dd8 100644
--- a/scripts/tf_cnn_benchmarks/models/mobilenet.py
+++ b/scripts/tf_cnn_benchmarks/models/mobilenet.py
@@ -23,7 +23,7 @@ import copy
 import os
 
 import tensorflow as tf
-
+tf.compat.v1.disable_eager_execution()
 slim = tf.contrib.slim
 
 
diff --git a/scripts/tf_cnn_benchmarks/models/model.py b/scripts/tf_cnn_benchmarks/models/model.py
index 708389a..c6fc7b6 100644
--- a/scripts/tf_cnn_benchmarks/models/model.py
+++ b/scripts/tf_cnn_benchmarks/models/model.py
@@ -17,6 +17,7 @@
 from collections import namedtuple
 
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
 import convnet_builder
 
@@ -194,14 +195,14 @@ class CNNModel(Model):
 
   def get_synthetic_inputs_and_labels(self, input_name, data_type, nclass):
     # Synthetic input should be within [0, 255].
-    inputs = tf.truncated_normal(
+    inputs = tf.compat.v1.truncated_normal(
         [self.batch_size] + self.get_input_shape(),
         dtype=data_type,
         mean=127,
         stddev=60,
         name=self.model_name + '_synthetic_inputs')
-    inputs = tf.contrib.framework.local_variable(inputs, name=input_name)
-    labels = tf.random_uniform(
+    # inputs = tf.contrib.framework.local_variable(inputs, name=input_name)
+    labels = tf.compat.v1.random_uniform(
         [self.batch_size],
         minval=0,
         maxval=nclass - 1,
@@ -235,7 +236,7 @@ class CNNModel(Model):
     network = convnet_builder.ConvNetBuilder(
         inputs, self.depth, phase_train, self.use_tf_layers, self.data_format,
         data_type, var_type)
-    with tf.variable_scope('cg', custom_getter=network.get_custom_getter()):
+    with tf.compat.v1.variable_scope('cg', custom_getter=network.get_custom_getter()):
       self.add_inference(network)
       # Add the final fully-connected class layer
       logits = (
@@ -261,12 +262,12 @@ class CNNModel(Model):
     # and once with the aux logits.
     aux_logits = build_network_result.extra_info
     with tf.name_scope('xentropy'):
-      cross_entropy = tf.losses.sparse_softmax_cross_entropy(
+      cross_entropy = tf.compat.v1.losses.sparse_softmax_cross_entropy(
           logits=logits, labels=labels)
       loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')
     if aux_logits is not None:
       with tf.name_scope('aux_xentropy'):
-        aux_cross_entropy = tf.losses.sparse_softmax_cross_entropy(
+        aux_cross_entropy = tf.compat.v1.losses.sparse_softmax_cross_entropy(
             logits=aux_logits, labels=labels)
         aux_loss = 0.4 * tf.reduce_mean(aux_cross_entropy, name='aux_loss')
         loss = tf.add_n([loss, aux_loss])
@@ -274,8 +275,10 @@ class CNNModel(Model):
 
   def accuracy_function(self, logits, labels, data_type):
     """Returns the ops to measure the accuracy of the model."""
+    # import pdb;pdb.set_trace()
+    # labels = tf.cast(labels, data_type)
     top_1_op = tf.reduce_sum(
-        tf.cast(tf.nn.in_top_k(logits, labels, 1), data_type))
+        tf.cast(tf.nn.in_top_k(labels, logits,  1), data_type))
     top_5_op = tf.reduce_sum(
-        tf.cast(tf.nn.in_top_k(logits, labels, 5), data_type))
+        tf.cast(tf.nn.in_top_k(labels, logits,  5), data_type))
     return {'top_1_accuracy': top_1_op, 'top_5_accuracy': top_5_op}
diff --git a/scripts/tf_cnn_benchmarks/models/model_config.py b/scripts/tf_cnn_benchmarks/models/model_config.py
index 1c08f04..fc6ab7f 100644
--- a/scripts/tf_cnn_benchmarks/models/model_config.py
+++ b/scripts/tf_cnn_benchmarks/models/model_config.py
@@ -23,15 +23,15 @@ from models import densenet_model
 from models import googlenet_model
 from models import inception_model
 from models import lenet_model
-from models import mobilenet_v2
-from models import nasnet_model
+# from models import mobilenet_v2
+# from models import nasnet_model
 from models import official_resnet_model
 from models import overfeat_model
 from models import resnet_model
 from models import ssd_model
 from models import trivial_model
 from models import vgg_model
-from models.experimental import deepspeech
+# from models.experimental import deepspeech
 from models.experimental import official_ncf_model
 
 
@@ -77,9 +77,9 @@ _model_name_to_imagenet_model = {
     'resnet101_v2': resnet_model.create_resnet101_v2_model,
     'resnet152': resnet_model.create_resnet152_model,
     'resnet152_v2': resnet_model.create_resnet152_v2_model,
-    'nasnet': nasnet_model.NasnetModel,
-    'nasnetlarge': nasnet_model.NasnetLargeModel,
-    'mobilenet': mobilenet_v2.MobilenetModel,
+    # 'nasnet': nasnet_model.NasnetModel,
+    # 'nasnetlarge': nasnet_model.NasnetLargeModel,
+    # 'mobilenet': mobilenet_v2.MobilenetModel,
     'ncf': official_ncf_model.NcfModel,
 }
 
@@ -100,7 +100,7 @@ _model_name_to_cifar_model = {
     'densenet40_k12': densenet_model.create_densenet40_k12_model,
     'densenet100_k12': densenet_model.create_densenet100_k12_model,
     'densenet100_k24': densenet_model.create_densenet100_k24_model,
-    'nasnet': nasnet_model.NasnetCifarModel,
+    # 'nasnet': nasnet_model.NasnetCifarModel,
 }
 
 
diff --git a/scripts/tf_cnn_benchmarks/models/nasnet_test.py b/scripts/tf_cnn_benchmarks/models/nasnet_test.py
index 115aa6c..d627603 100644
--- a/scripts/tf_cnn_benchmarks/models/nasnet_test.py
+++ b/scripts/tf_cnn_benchmarks/models/nasnet_test.py
@@ -243,10 +243,10 @@ class NASNetTest(tf.test.TestCase):
     inputs = tf.random_uniform((batch_size, height, width, 3))
     tf.train.create_global_step()
     # Force all Variables to reside on the device.
-    with tf.variable_scope('on_cpu'), tf.device('/cpu:0'):
+    with tf.variable_scope('on_cpu'), tf.compat.v1.device('/cpu:0'):
       with slim.arg_scope(nasnet.nasnet_mobile_arg_scope()):
         nasnet.build_nasnet_mobile(inputs, num_classes)
-    with tf.variable_scope('on_gpu'), tf.device('/gpu:0'):
+    with tf.variable_scope('on_gpu'), tf.compat.v1.device('/gpu:0'):
       with slim.arg_scope(nasnet.nasnet_mobile_arg_scope()):
         nasnet.build_nasnet_mobile(inputs, num_classes)
     for v in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='on_cpu'):
diff --git a/scripts/tf_cnn_benchmarks/models/nasnet_utils.py b/scripts/tf_cnn_benchmarks/models/nasnet_utils.py
index afe2edd..255e3da 100644
--- a/scripts/tf_cnn_benchmarks/models/nasnet_utils.py
+++ b/scripts/tf_cnn_benchmarks/models/nasnet_utils.py
@@ -435,7 +435,7 @@ class NasNetABaseCell(object):
         num_cells = self._total_num_cells
         layer_ratio = (self._cell_num + 1) / float(num_cells)
         if use_summaries:
-          with tf.device('/cpu:0'):
+          with tf.compat.v1.device('/cpu:0'):
             tf.summary.scalar('layer_ratio', layer_ratio)
         drop_path_keep_prob = 1 - layer_ratio * (1 - drop_path_keep_prob)
       if drop_connect_version in ['v1', 'v3']:
@@ -447,11 +447,11 @@ class NasNetABaseCell(object):
         current_ratio = current_step / drop_path_burn_in_steps
         current_ratio = tf.minimum(1.0, current_ratio)
         if use_summaries:
-          with tf.device('/cpu:0'):
+          with tf.compat.v1.device('/cpu:0'):
             tf.summary.scalar('current_ratio', current_ratio)
         drop_path_keep_prob = (1 - current_ratio * (1 - drop_path_keep_prob))
       if use_summaries:
-        with tf.device('/cpu:0'):
+        with tf.compat.v1.device('/cpu:0'):
           tf.summary.scalar('drop_path_keep_prob', drop_path_keep_prob)
       net = drop_path(net, drop_path_keep_prob)
     return net
diff --git a/scripts/tf_cnn_benchmarks/models/resnet_model.py b/scripts/tf_cnn_benchmarks/models/resnet_model.py
index 8275d2c..9a34339 100644
--- a/scripts/tf_cnn_benchmarks/models/resnet_model.py
+++ b/scripts/tf_cnn_benchmarks/models/resnet_model.py
@@ -35,6 +35,7 @@ from __future__ import division
 import numpy as np
 from six.moves import xrange  # pylint: disable=redefined-builtin
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 import datasets
 from models import model as model_lib
 
@@ -54,7 +55,7 @@ def bottleneck_block_v1(cnn, depth, depth_bottleneck, stride):
   name = name_key + str(cnn.counts[name_key])
   cnn.counts[name_key] += 1
 
-  with tf.variable_scope(name):
+  with tf.compat.v1.variable_scope(name):
     if depth == in_size:
       if stride == 1:
         shortcut = input_layer
@@ -102,7 +103,7 @@ def bottleneck_block_v1_5(cnn, depth, depth_bottleneck, stride):
   name = name_key + str(cnn.counts[name_key])
   cnn.counts[name_key] += 1
 
-  with tf.variable_scope(name):
+  with tf.compat.v1.variable_scope(name):
     if depth == in_size:
       if stride == 1:
         shortcut = input_layer
@@ -148,7 +149,7 @@ def bottleneck_block_v2(cnn, depth, depth_bottleneck, stride):
 
   preact = cnn.batch_norm()
   preact = tf.nn.relu(preact)
-  with tf.variable_scope(name):
+  with tf.compat.v1.variable_scope(name):
     if depth == in_size:
       if stride == 1:
         shortcut = input_layer
@@ -301,7 +302,7 @@ class ResnetModel(model_lib.CNNModel):
     boundaries = [int(num_batches_per_epoch * x) for x in [30, 60, 80, 90]]
     values = [1, 0.1, 0.01, 0.001, 0.0001]
     values = [rescaled_lr * v for v in values]
-    lr = tf.train.piecewise_constant(global_step, boundaries, values)
+    lr = tf.compat.v1.train.piecewise_constant(global_step, boundaries, values)
     warmup_steps = int(num_batches_per_epoch * 5)
     warmup_lr = (
         rescaled_lr * tf.cast(global_step, tf.float32) / tf.cast(
@@ -407,7 +408,7 @@ class ResnetCifar10Model(model_lib.CNNModel):
                                                   dtype=np.int64)
     boundaries = [x for x in boundaries]
     values = [0.1, 0.01, 0.001, 0.0002]
-    return tf.train.piecewise_constant(global_step, boundaries, values)
+    return tf.compat.v1.train.piecewise_constant(global_step, boundaries, values)
 
 
 def create_resnet20_cifar_model(params):
diff --git a/scripts/tf_cnn_benchmarks/preprocessing.py b/scripts/tf_cnn_benchmarks/preprocessing.py
index 4b97ec6..ef2d224 100644
--- a/scripts/tf_cnn_benchmarks/preprocessing.py
+++ b/scripts/tf_cnn_benchmarks/preprocessing.py
@@ -23,8 +23,9 @@ from __future__ import print_function
 import math
 from six.moves import xrange  # pylint: disable=redefined-builtin
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
-from tensorflow.contrib.image.python.ops import distort_image_ops
+# from tensorflow.contrib.image.python.ops import distort_image_ops
 from tensorflow.python.layers import utils
 from tensorflow.python.ops import data_flow_ops
 from tensorflow.python.platform import gfile
diff --git a/scripts/tf_cnn_benchmarks/test_util.py b/scripts/tf_cnn_benchmarks/test_util.py
index 6ae98cf..3158364 100644
--- a/scripts/tf_cnn_benchmarks/test_util.py
+++ b/scripts/tf_cnn_benchmarks/test_util.py
@@ -362,7 +362,7 @@ def manually_compute_losses(numpy_inputs, inputs_placeholder, loss, num_workers,
   images from `inputs_placeholder`, a tf.placeholder, and computes `loss`.
 
   This function, and all ops passed to this function, must be run under a
-  tf.device('cpu:0') context manager.
+  tf.compat.v1.device('cpu:0') context manager.
 
   Non-SGD optimizers are not supported with multiple workers.
 
@@ -475,7 +475,7 @@ class TestCNNModel(model.CNNModel):
     return tf.reduce_mean(build_network_result.logits)
 
   def manually_compute_losses(self, inputs, num_workers, params):
-    with tf.Graph().as_default(), tf.device('/cpu:0'):
+    with tf.Graph().as_default(), tf.compat.v1.device('/cpu:0'):
       a = tf.Variable(self.VAR_A_INITIAL_VALUE, name='A')
       b = tf.Variable(self.VAR_B_INITIAL_VALUE, name='B')
       inputs_placeholder = tf.placeholder(tf.float32,
diff --git a/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py b/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py
index 6d6636c..2b05d7a 100644
--- a/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py
+++ b/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py
@@ -23,6 +23,7 @@ from __future__ import print_function
 from absl import app
 from absl import flags as absl_flags
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
 import benchmark_cnn
 import cnn_util
diff --git a/scripts/tf_cnn_benchmarks/variable_mgr.py b/scripts/tf_cnn_benchmarks/variable_mgr.py
index 4ec2c83..d3eedad 100644
--- a/scripts/tf_cnn_benchmarks/variable_mgr.py
+++ b/scripts/tf_cnn_benchmarks/variable_mgr.py
@@ -21,6 +21,7 @@ from __future__ import print_function
 import re
 
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
 import allreduce
 import batch_allreduce
@@ -116,7 +117,7 @@ class VariableMgr(object):
 
   def savable_variables(self):
     """Returns a list/dict of savable variables to pass to tf.train.Saver."""
-    return tf.global_variables()
+    return tf.compat.v1.global_variables()
 
   def trainable_variables_on_device(self,
                                     rel_device_num,
@@ -135,11 +136,11 @@ class VariableMgr(object):
     del rel_device_num, writable
     if self.each_tower_has_variables():
       params = [
-          v for v in tf.trainable_variables()
+          v for v in tf.compat.v1.trainable_variables()
           if v.name.startswith('v%s/' % abs_device_num)
       ]
     else:
-      params = tf.trainable_variables()
+      params = tf.compat.v1.trainable_variables()
     return params
 
 
@@ -192,7 +193,7 @@ class VariableMgrLocalFetchFromPS(VariableMgr):
     return False
 
   def create_outer_variable_scope(self, device_num):
-    return tf.variable_scope('v', reuse=bool(device_num),
+    return tf.compat.v1.variable_scope('v', reuse=bool(device_num),
                              use_resource=self.use_resource_vars)
 
   def preprocess_device_grads(self, device_grads):
@@ -583,12 +584,12 @@ class VariableMgrCollectiveAllReduce(VariableMgr):
         if mo:
           device_id = int(mo.group(1))
           if (self._task_id == 0 and device_id == 0):
-            with tf.device(v.device):
+            with tf.compat.v1.device(v.device):
               bcast_send = allreduce.broadcast_send(
                   v, v.shape, v.dtype, group_size, group_key, instance_key)
               post_init_ops.append(v.assign(bcast_send))
           else:
-            with tf.device(v.device):
+            with tf.compat.v1.device(v.device):
               bcast_recv = allreduce.broadcast_recv(
                   v.shape, v.dtype, group_size, group_key, instance_key)
               post_init_ops.append(v.assign(bcast_recv))
@@ -743,7 +744,7 @@ class VariableMgrDistributedReplicated(VariableMgr):
         barrier = self.benchmark_cnn.add_sync_queues_and_barrier(
             'replicate_variable_%s' % i, [apply_gradient_op])
         with tf.control_dependencies([barrier]):
-          with tf.device(self.benchmark_cnn.cpu_device):
+          with tf.compat.v1.device(self.benchmark_cnn.cpu_device):
             updated_value = v.read_value()
             for my_d in range(len(self.benchmark_cnn.devices)):
               apply_gradients_ops.append(
@@ -790,7 +791,7 @@ class VariableMgrDistributedReplicated(VariableMgr):
   def savable_variables(self):
     """Returns a list/dict of savable variables to pass to tf.train.Saver."""
     params = {}
-    for v in tf.global_variables():
+    for v in tf.compat.v1.global_variables():
       assert (v.name.startswith(variable_mgr_util.PS_SHADOW_VAR_PREFIX + '/v0/')
               or v.name in ('global_step:0', 'loss_scale:0',
                             'loss_scale_normal_steps:0')), (
@@ -801,12 +802,12 @@ class VariableMgrDistributedReplicated(VariableMgr):
       # distributed_replicated mode.
       name = self._strip_port(self._remove_shadow_var_prefix_if_present(v.name))
       params[name] = v
-    for v in tf.local_variables():
+    for v in tf.compat.v1.local_variables():
       # Non-trainable variables, such as batch norm moving averages, do not have
       # corresponding global shadow variables, so we add them here. Trainable
       # local variables have corresponding global shadow variables, which were
       # added in the global variable loop above.
-      if v.name.startswith('v0/') and v not in tf.trainable_variables():
+      if v.name.startswith('v0/') and v not in tf.compat.v1.trainable_variables():
         params[self._strip_port(v.name)] = v
     return params
 
diff --git a/scripts/tf_cnn_benchmarks/variable_mgr_util.py b/scripts/tf_cnn_benchmarks/variable_mgr_util.py
index 7e589dc..ba78062 100644
--- a/scripts/tf_cnn_benchmarks/variable_mgr_util.py
+++ b/scripts/tf_cnn_benchmarks/variable_mgr_util.py
@@ -20,6 +20,7 @@ import collections as pycoll
 import operator
 
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 
 from tensorflow.python.framework import ops
 from tensorflow.python.ops import data_flow_ops
@@ -286,7 +287,7 @@ class StagedModelVariable(object):
 
     # colocate_with(None, True) clears the colocation constraints.
     # Push the delta into a staging buffer.
-    with ops.colocate_with(None, True), tf.device(self.var_stage_get.device):
+    with ops.colocate_with(None, True), tf.compat.v1.device(self.var_stage_get.device):
       delta_staging_area = data_flow_ops.StagingArea(
           [self.var_stage_get.dtype], shapes=[self.var_stage_get.shape])
       delta_put_op = delta_staging_area.put([delta])
@@ -342,7 +343,7 @@ class StagedVariableGetter(object):
     dtype = kwargs['dtype']
     trainable = kwargs['trainable']
     if self.cpu_device:
-      with tf.device(self.cpu_device):
+      with tf.compat.v1.device(self.cpu_device):
         # This helps copying the weights from the parameter to this server only
         # once.
         if name in self.variable_mgr.staged_vars_on_cpu:
@@ -354,7 +355,7 @@ class StagedVariableGetter(object):
     else:
       var_to_stage = tf.identity(real_var)  # de-reference the variable.
 
-    with tf.device(self.devices[self.device_num]):
+    with tf.compat.v1.device(self.devices[self.device_num]):
       staging_area = data_flow_ops.StagingArea([dtype], shapes=[shape])
       put_op = staging_area.put([var_to_stage])
       get_op = staging_area.get()[0]
@@ -416,7 +417,7 @@ def aggregate_gradients_using_copy_with_device_selection(
   agg_grads = []
   has_nan_or_inf_list = []
   for i, single_grads in enumerate(zip(*tower_grads)):
-    with tf.device(avail_devices[i % len(avail_devices)]):
+    with tf.compat.v1.device(avail_devices[i % len(avail_devices)]):
       grad_and_var, has_nan_or_inf = aggregate_single_gradient_using_copy(
           single_grads, use_mean, check_inf_nan)
       agg_grads.append(grad_and_var)
@@ -454,7 +455,7 @@ def aggregate_gradients_using_copy_with_variable_colocation(
     for _, v in single_grads:
       assert v == var
 
-    with tf.device(var.device):
+    with tf.compat.v1.device(var.device):
       grad_and_var, has_nan_or_inf = aggregate_single_gradient_using_copy(
           single_grads, use_mean, check_inf_nan)
       agg_grads.append(grad_and_var)
